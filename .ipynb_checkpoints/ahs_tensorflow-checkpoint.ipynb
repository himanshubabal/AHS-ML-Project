{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation\n",
    "# from keras.optimizers import SGD\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Splitting train and test data in ratio 85:15\n"
     ]
    }
   ],
   "source": [
    "diagnosed_data = pd.read_csv(data_path + '22_COMB_diag_hotData.csv', low_memory=False)\n",
    "diagnosed_col = pd.read_csv(data_path + '22_COMB_diag_col.csv', low_memory=False)\n",
    "\n",
    "if 'Unnamed: 0' in list(diagnosed_col):\n",
    "\tdiagnosed_col = diagnosed_col.drop('Unnamed: 0',axis=1,errors='ignore')\n",
    "\n",
    "assert (diagnosed_data.shape[0] == diagnosed_col.shape[0])\n",
    "split_index = int(diagnosed_data.shape[0] * 0.85)\n",
    "\n",
    "print('   ')\n",
    "print('Splitting train and test data in ratio 85:15')\n",
    "train_data = np.array(diagnosed_data.astype(float))[:split_index]\n",
    "train_label = np.array(diagnosed_col.astype(float))[:split_index][:,0]\n",
    "\n",
    "test_data = np.array(diagnosed_data.astype(float))[split_index:]\n",
    "test_label = np.array(diagnosed_col.astype(float))[split_index:][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((158036, 303), (158036, 1))\n"
     ]
    }
   ],
   "source": [
    "print(diagnosed_data.shape, diagnosed_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list = [1.0,2.0,3.0,7.0,9.0,19.0,21.0,99.0]\n",
    "new_list = [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace Label No 99 by 32\n",
    "# Label No 99 causes 'to_categorical' to make 100 one-hot values\n",
    "# Replacing it by 33 leads to only 33 values\n",
    "def replace_99_labes(label_data):\n",
    "    for i in range(len(label_data)):\n",
    "        e = label_data[i]\n",
    "        if e in pred_list:\n",
    "            ind = pred_list.index(label_data[i])\n",
    "            new_element = new_list[ind]\n",
    "            label_data[i] = new_element\n",
    "        else:\n",
    "            label_data[i] = 0\n",
    "# \t\tif label_data[i] == 99.0 :\n",
    "# \t\t\tlabel_data[i] = 32.0\n",
    "    return label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_keep_value = 1.0\n",
    "\n",
    "def binary_labels(label_data):\n",
    "    for i in range(len(label_data)):\n",
    "        if label_data[i] != 1.0 :\n",
    "            label_data[i] = 0.0\n",
    "# \t\tif label_data[i] == 99.0 :\n",
    "# \t\t\tlabel_data[i] = 32.0\n",
    "    return label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_rep = replace_99_labes(train_label)\n",
    "# test_rep = replace_99_labes(test_label)\n",
    "\n",
    "train_rep = binary_labels(train_label)\n",
    "test_rep = binary_labels(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((134330, 303), (134330,))\n",
      "((23706, 303), (23706,))\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, train_rep.shape)\n",
    "print(test_data.shape, test_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rep[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def onehot_labels(labels):\n",
    "    print(labels.shape)\n",
    "    if len(labels.shape) < 2:\n",
    "        labels = labels.reshape(-1,1)\n",
    "    enc = OneHotEncoder()\n",
    "    return (enc.fit_transform(labels).toarray())\n",
    "\n",
    "# (134330,1)  -->  (134330, 9)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23706,)\n",
      "(134330,)\n",
      "((134330, 2), (23706, 2))\n"
     ]
    }
   ],
   "source": [
    "test_label_hot = onehot_labels(test_rep)\n",
    "train_label_hot = onehot_labels(train_rep)\n",
    "\n",
    "print(train_label_hot.shape, test_label_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Y1 : ', TensorShape([Dimension(None), Dimension(100)]))\n",
      "('Y2 : ', TensorShape([Dimension(None), Dimension(75)]))\n",
      "('Y3 : ', TensorShape([Dimension(None), Dimension(50)]))\n",
      "('YF : ', TensorShape([Dimension(None), Dimension(2)]))\n",
      "('Yf : ', TensorShape([Dimension(None), Dimension(2)]))\n",
      "('YY : ', TensorShape([Dimension(None)]))\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "def hidden_layer(input, size_in, size_out, name='hidden'):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "        \n",
    "#         tf.summary.histogram(\"weights\", w)\n",
    "#         tf.summary.histogram(\"biases\", b)\n",
    "#         tf.summary.histogram(\"activations\", act)\n",
    "        \n",
    "        return act\n",
    "    \n",
    "with graph.as_default():\n",
    "    SIZE = train_data.shape[1]\n",
    "    HOT = train_label_hot.shape[1]\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, SIZE])\n",
    "    Y_ = tf.placeholder(tf.float32, [None, HOT])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    K = 100    # Neurons in 1st hidden layer\n",
    "    L = 75     # Neurons in 2nd hidden layer\n",
    "    M = 50     # Neurons in 3rd hidden layer\n",
    "    \n",
    "    Y1 = hidden_layer(X, SIZE, K, name='hidden-1')\n",
    "    Y2 = hidden_layer(Y1, K, L, name='hidden-2')\n",
    "    Y3 = hidden_layer(Y2, L, M, name='hidden-3')\n",
    "    Y_drop = tf.nn.dropout(Y3, pkeep)\n",
    "    YF = hidden_layer(Y_drop, M, HOT, name='output')\n",
    "    \n",
    "#     W1 = tf.Variable(tf.truncated_normal([SIZE, K], stddev=0.1), name=\"W1\")\n",
    "#     B1 = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[K]), name=\"B1\")\n",
    "    \n",
    "#     W2 = tf.Variable(tf.truncated_normal([K, L], stddev=0.1), name=\"W2\")\n",
    "#     B2 = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[L]), name=\"B2\")\n",
    "    \n",
    "#     W3 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1), name=\"W3\")\n",
    "#     B3 = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[M]), name=\"B3\")\n",
    "    \n",
    "#     WF = tf.Variable(tf.truncated_normal([M, HOT], stddev=0.1), name=\"WF\")\n",
    "#     BF = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[HOT]), name=\"BF\")\n",
    "    \n",
    "#     print(W1.get_shape(), W2.get_shape())\n",
    "#     print(W3.get_shape(), WF.get_shape())\n",
    "#     print(B1.get_shape(), B2.get_shape())\n",
    "#     print(B3.get_shape(), BF.get_shape()) \n",
    "    \n",
    "#     # Model\n",
    "#     Y1 = tf.nn.relu(tf.matmul(X, W1) + B1)      # Shape -> \n",
    "#     Y2 = tf.nn.relu(tf.matmul(Y1, W2) + B2)     # Shape -> \n",
    "#     Y3 = tf.nn.relu(tf.matmul(Y2, W3) + B3)     # Shape ->\n",
    "#     YF = tf.nn.relu(tf.matmul(tf.nn.dropout(Y3, pkeep), WF) + BF)     # Shape ->\n",
    "    \n",
    "    print('Y1 : ',Y1.get_shape())\n",
    "    print('Y2 : ',Y2.get_shape())\n",
    "    print('Y3 : ',Y3.get_shape())\n",
    "    print('YF : ',YF.get_shape())\n",
    "    \n",
    "    Y_f = tf.nn.softmax(YF)\n",
    "    \n",
    "    YY = tf.nn.softmax_cross_entropy_with_logits(logits=Y_f, labels=Y_)\n",
    "#     YY = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=Y_f, labels=Y_)\n",
    "    \n",
    "#     YY = -tf.reduce_sum(Y_ * tf.log(Y_f), [1])\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(YY)\n",
    "    \n",
    "    print('Yf : ',Y_f.get_shape())\n",
    "    print('YY : ',YY.get_shape())\n",
    "    \n",
    "#     cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=YF, labels=Y_))\n",
    "    \n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "\n",
    "    train_prediction = tf.pack([YF, Y_f])\n",
    "    YYY = tf.pack([YY])\n",
    "    yy_ = tf.pack([Y_])\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(Y_f,1), tf.argmax(Y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3))\\\n",
    "                   ,tf.reduce_max(tf.abs(WF))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3))\\\n",
    "                   ,tf.reduce_max(tf.abs(BF))])\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train : ', (134330, 303), '  test : ', (134330, 2))\n",
      "Initialized\n",
      "Loss at step 0: 0.699335\n",
      "Minibatch accuracy: 64.844%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.524938\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.511901\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.509427\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508674\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508635\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508585\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508612\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508581\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508576\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508576\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508575\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 0: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Loss at step 500: 0.453887\n",
      "Minibatch accuracy: 85.938%\n",
      "    \n",
      "Loss at step 1000: 0.508574\n",
      "Minibatch accuracy: 80.469%\n",
      "    \n",
      "Training Complete on MNIST Data\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/models/1_label/label_1.ckpt.tempstate10509209658742328678\n\t [[Node: save/save = SaveSlices[T=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/save/tensor_names, save/save/shapes_and_slices, B1/_45, B1/Adam/_47, B1/Adam_1/_49, B2/_51, B2/Adam/_53, B2/Adam_1/_55, B3/_57, B3/Adam/_59, B3/Adam_1/_61, BF/_63, BF/Adam/_65, BF/Adam_1/_67, W1/_69, W1/Adam/_71, W1/Adam_1/_73, W2/_75, W2/Adam/_77, W2/Adam_1/_79, W3/_81, W3/Adam/_83, W3/Adam_1/_85, WF/_87, WF/Adam/_89, WF/Adam_1/_91, beta1_power/_93, beta2_power/_95)]]\nCaused by op u'save/save', defined at:\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-144-b538f1a2b2d6>\", line 87, in <module>\n    model_saver = tf.train.Saver()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 784, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 452, in build\n    save_tensor = self._AddSaveOps(filename_tensor, vars_to_save)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 153, in _AddSaveOps\n    save = self.save_op(filename_tensor, vars_to_save)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 105, in save_op\n    tensor_slices=[vs.slice_spec for vs in vars_to_save])\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 169, in _save\n    tensors, name=name)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 341, in _save_slices\n    name=name)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 661, in apply_op\n    op_def=op_def)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-240c4444cf4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m#     print('Test Accuracy : ', mean(test_acc))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/models/1_label/label_1.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model saved in file: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix)\u001b[0m\n\u001b[0;32m    960\u001b[0m     model_checkpoint_path = sess.run(\n\u001b[0;32m    961\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m         {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m    963\u001b[0m     \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m     self._MaybeDeleteOldCheckpoints(model_checkpoint_path,\n",
      "\u001b[1;32m/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 586\u001b[1;33m                                               e.code)\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: /models/1_label/label_1.ckpt.tempstate10509209658742328678\n\t [[Node: save/save = SaveSlices[T=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/save/tensor_names, save/save/shapes_and_slices, B1/_45, B1/Adam/_47, B1/Adam_1/_49, B2/_51, B2/Adam/_53, B2/Adam_1/_55, B3/_57, B3/Adam/_59, B3/Adam_1/_61, BF/_63, BF/Adam/_65, BF/Adam_1/_67, W1/_69, W1/Adam/_71, W1/Adam_1/_73, W2/_75, W2/Adam/_77, W2/Adam_1/_79, W3/_81, W3/Adam/_83, W3/Adam_1/_85, WF/_87, WF/Adam/_89, WF/Adam_1/_91, beta1_power/_93, beta2_power/_95)]]\nCaused by op u'save/save', defined at:\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-144-b538f1a2b2d6>\", line 87, in <module>\n    model_saver = tf.train.Saver()\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 784, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 452, in build\n    save_tensor = self._AddSaveOps(filename_tensor, vars_to_save)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 153, in _AddSaveOps\n    save = self.save_op(filename_tensor, vars_to_save)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 105, in save_op\n    tensor_slices=[vs.slice_spec for vs in vars_to_save])\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 169, in _save\n    tensors, name=name)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 341, in _save_slices\n    name=name)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 661, in apply_op\n    op_def=op_def)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/apps/TENSOR_GPU/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data\n",
    "label_data = train_label_hot   #[:,np.newaxis]\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_steps = int(label_data.shape[0] / batch_size)\n",
    "num_epochs = 25\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables()\n",
    "    \n",
    "    init_op = tf.initialize_all_variables()\n",
    "\n",
    "    session.run(init_op)\n",
    "#     tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "\n",
    "#     test_batch = int(svhn_test_box_labels.shape[0]/num_epochs)\n",
    "#     test_acc = list()\n",
    "    \n",
    "    for epoch in range(num_epochs - 1):\n",
    "#         res_epoch = {}\n",
    "#         t_data = svhn_test_box_dataset[epoch*test_batch:(epoch+1)*test_batch]\n",
    "#         t_label = svhn_test_box_labels[epoch*test_batch:(epoch+1)*test_batch]\n",
    "        \n",
    "        for step in range(num_steps - 1):\n",
    "            max_learning_rate = 0.0005\n",
    "            min_learning_rate = 0.0001\n",
    "\n",
    "            decay_speed = 5000.0\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "\n",
    "            batch_data = train_data[step*batch_size:(step + 1)*batch_size,:]\n",
    "#             batch_labels = label_data[step*batch_size:(step + 1)*batch_size, :]\n",
    "            batch_labels = label_data[step*batch_size:(step + 1)*batch_size]\n",
    "\n",
    "            feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "            _, l, train_pred, yyy, y_, w, b, accc = session.run([train_step, cross_entropy, train_prediction, YYY, yy_, W_s, b_s, accuracy], feed_dict=feed_dict)\n",
    "            \n",
    "#             accuracy = float(acc(train_pred[0], batch_labels))\n",
    "\n",
    "            if (step % 500 == 0):\n",
    "#                 print('Input : ',y_)\n",
    "#                 print(' ')\n",
    "#                 print('YF - W*X+b : ',train_pred[0])\n",
    "#                 print(' ')\n",
    "#                 print('Y_f- soft(): ',train_pred[1])\n",
    "#                 print(' ')\n",
    "#                 print('YY - CE on soft :',yyy)\n",
    "#                 print(' ')\n",
    "#                 print('Weights : ', w)\n",
    "#                 print('Biases : ', b)\n",
    "#                 minibatch = {}\n",
    "#                 minibatch['loss'] = l\n",
    "#                 minibatch['W'] = W\n",
    "#                 minibatch['B'] = b\n",
    "#                 minibatch['accuracy'] = \"%.2f\" % accuracy\n",
    "\n",
    "#                 res_epoch[int(step/500)] = minibatch\n",
    "                print('Loss at step %d: %f' % (step, l))\n",
    "#                 print('----------------------------')\n",
    "                print('Minibatch accuracy: %.3f%%' % (accc*100))  #(train_pred, batch_labels))\n",
    "                print('    ')\n",
    "                \n",
    "#         box_train_dict[epoch+1] = res_epoch\n",
    "\n",
    "#         epoch_acc = 0\n",
    "#         for f in res_epoch:\n",
    "#             minibatch = res_epoch[f]\n",
    "#             epoch_acc += float(minibatch['accuracy'])\n",
    "#         epoch_acc = float(epoch_acc/len(res_epoch))\n",
    "        \n",
    "#         _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : t_data, Y_ : t_label, pkeep : 1.0, alpha : 0.002})\n",
    "#         accuracy = float(acc(predictions, t_label[:,1:6]))\n",
    "#         test_acc.append(accuracy)\n",
    "\n",
    "#         print('------------------------------------')\n",
    "#         print('Epoch',epoch+1,' Complete with accuracy: %.2f%%' % epoch_acc)\n",
    "#         print('Epoch',epoch+1,' Test Accuracy : %.2f%%' % accuracy)\n",
    "#         print('------------------------------------')\n",
    "#         print('        ')\n",
    "            \n",
    "    print('Training Complete on MNIST Data')\n",
    "#     print('Test Accuracy : ', mean(test_acc))\n",
    "    \n",
    "    save_path = model_saver.save(session, '/models/1_label/label_1.ckpt')\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
